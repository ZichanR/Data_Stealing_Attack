# Data_Stealing_Attack

### Problem Statement

Adversarial attacks have posed serious security concerns for DNN applications in critical sectors. At the same time, adversarial training (AT) is the most effective method to defend against adversarial attacks empirically. Additionally, the adversarially trained robust models show better transferability to downstream tasks [1], improve generalizations on clean samples [2], and align with human perceptions [3]. These intriguing properties of the robust model motivate studies in AT. However, AT is also known to be time-consuming. In each optimization step, the model needs to generate an adversarial example by performing several forward and backward passes. This becomes a major bottleneck. However, although there are attempts to accelerate the AT [4, 5], efficient AT on large-scale datasets still needs to be solved.

### Project Goals 
- **Efficient adversarial training at scale:**
- **Adversarial robust pre-training:**
`NoteïŒ`
`Code:` You may follow the following as an example


### Reference 
